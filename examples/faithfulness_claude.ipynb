{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/rageval_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-07-16 20:18:56,092\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ubuntu/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-16 20:18:57,071\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "from fmeval.data_loaders.data_config import DataConfig\n",
    "from fmeval.model_runners.bedrock_model_runner import BedrockModelRunner\n",
    "from fmeval.constants import MIME_TYPE_JSONLINES\n",
    "from fmeval.eval_algorithms.faithfulness import Faithfulness\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DataConfig(\n",
    "    dataset_name=\"rag-dataset-refs-test-100\",\n",
    "    dataset_uri=\"rag-dataset-refs-test-100.jsonl\",\n",
    "    dataset_mime_type=MIME_TYPE_JSONLINES,\n",
    "    model_input_location=\"question_with_prompt\",\n",
    "    model_output_location=\"answer\",\n",
    "    target_context_location=\"target_context\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['AWS_DEFAULT_REGION'] = 'us-west-2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/home/ubuntu/efs/clarify_rag/rag_eval/results-eval-faithfulness/' exists.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "eval_dir = \"results-eval-faithfulness\"\n",
    "curr_dir = os.getcwd()\n",
    "eval_results_path = os.path.join(curr_dir, eval_dir) + \"/\"\n",
    "os.environ[\"EVAL_RESULTS_PATH\"] = eval_results_path\n",
    "if os.path.exists(eval_results_path):\n",
    "    print(f\"Directory '{eval_results_path}' exists.\")\n",
    "else:\n",
    "    os.mkdir(eval_results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "claude3_sonnet_model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "claude3_haiku_model_id = \"anthropic.claude-3-haiku-20240307-v1:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from https://aws.amazon.com/bedrock/pricing/\n",
    "claude3_cost = {\n",
    "    claude3_haiku_model_id: {\n",
    "        'pp1k_input_tokens': 0.00025,\n",
    "        'pp1k_output_tokens': 0.00125,\n",
    "    },\n",
    "    claude3_sonnet_model_id: {\n",
    "        'pp1k_input_tokens': 0.003,\n",
    "        'pp1k_output_tokens': 0.015,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"anthropic_version\": \"bedrock-2023-05-31\", \"max_tokens\": 10000, \"temperature\": 0.0, \"messages\": [{\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": $prompt}]}]}'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_template = {\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 10000,\n",
    "        \"temperature\": 0.0,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": -1},\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "content_template = json.dumps(content_template)\n",
    "content_template = content_template.replace('-1', '$prompt')\n",
    "content_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bedrock_model(model_id, output_jmespath) -> BedrockModelRunner:\n",
    "    \"\"\"Get default judge model\n",
    "\n",
    "    :return: A Bedrock Model Runner with default model id.\n",
    "    \"\"\"\n",
    "    return BedrockModelRunner(\n",
    "        model_id=model_id,\n",
    "        output=output_jmespath,\n",
    "        content_template=content_template,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = claude3_haiku_model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_model = get_bedrock_model(model_id, \"content[0].text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crafting a prompt using Anthropic cookbook [guidelines](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/use-xml-tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_form_example = \"\"\"\n",
    "<example>\n",
    "<text>\n",
    "Question: Who was Albert Einstein and what is he best known for?\n",
    "Answer: Albert Einstein was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\n",
    "</text>\n",
    "<statements>\n",
    "Statement: Albert Einstein was a German-born theoretical physicist.\n",
    "Statement: Albert Einstein is recognized as one of the greatest and most influential physicists of all time.\n",
    "Statement: Albert Einstein was best known for developing the theory of relativity.\n",
    "Statement: Albert Einstein also made important contributions to the development of the theory of quantum mechanics.\n",
    "</statements>\n",
    "</example>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nli_statements_example = \"\"\"\n",
    "<example>\n",
    "<context>\n",
    "John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.\n",
    "</context>\n",
    "<statements>\n",
    "Statement: John is majoring in Biology.\n",
    "Statement: John is taking a course on Artificial Intelligence.\n",
    "Statement: John is a dedicated student.\n",
    "Statement: John has a part-time job.\n",
    "Statement: John is interested in computer programming.\n",
    "</statements>\n",
    "<judgements>\n",
    "<judgement>\n",
    "Statement: John is majoring in Biology.\n",
    "Verdict: No\n",
    "Explanation: John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.  Verdict: No.\n",
    "</judgement>\n",
    "<judgement>\n",
    "Statement: John is taking a course on Artificial Intelligence.\n",
    "Verdict: No\n",
    "Explanation: The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI. Verdict: No.\n",
    "</judgement>\n",
    "<judgement>\n",
    "Statement: John is a dedicated student.\n",
    "Verdict: Yes\n",
    "Explanation: The prompt states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication. Verdict: Yes.\n",
    "</judgement>\n",
    "<judgement>\n",
    "Statement: John has a part-time job.\n",
    "Verdict: No\n",
    "Explanation: There is no information given in the context about John having a part-time job. Therefore, it cannot be deduced that John has a part-time job.  Verdict: No.\n",
    "</judgement>\n",
    "<judgement>\n",
    "Statement: John is interested in computer programming.\n",
    "Verdict: Yes\n",
    "Explanation: The context states that John is pursuing a degree in Computer Science, which implies an interest in computer programming. Verdict: Yes.\n",
    "</judgement>\n",
    "</judgements>\n",
    "</example>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_form_prompt_template = f\"\"\"Human:\n",
    "<text>\n",
    "Question: $question\n",
    "Answer: $answer\n",
    "</text>\n",
    "\n",
    "You are given a question and answer within the <text> tags above.\n",
    "Your task is to break down the answer into one or more simple, meaningful and unique statements.\n",
    "Your statements should contain all the details and facts present in the answer.\n",
    "Please do not generate redundant statements.\n",
    "You should start each statement with the tag \"Statement: \". Place your statements within the <statements> tags.\n",
    "To help you understand the task and the output format, you are given an example below within the <example> tags.\n",
    "\n",
    "{long_form_example}\n",
    "\n",
    "Assistant:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "nli_statements_prompt_template = f\"\"\"Human:\n",
    "<text>\n",
    "<context>\n",
    "$context\n",
    "</context>\n",
    "<statements>\n",
    "$statements\n",
    "</statements>\n",
    "</text>\n",
    "\n",
    "You are given a context within <context> tags and some statements within <statements> tags above.\n",
    "For each given statement, your task is to judge if the statement can be inferred from the given context.\n",
    "If a statement can be inferred from the given context, output your judgement as \"Verdict: yes\". Else, output \"Verdict: no\".\n",
    "For each judgement also provide a simple and short explanation. Place your judgements within <judgements> tags.\n",
    "To help you understand the task and the output format, you are given an example below within the <example> tags.\n",
    "\n",
    "{nli_statements_example}\n",
    "\n",
    "Assistant:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-17 03:01:25,181\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-07-16_20-19-30_230780_1258974/logs/ray-data\n",
      "2024-07-17 03:01:25,182\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> AllToAllOperator[Repartition]\n",
      "\n",
      "                                                  \n",
      "\u001b[A2024-07-17 03:01:25,874\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-07-16_20-19-30_230780_1258974/logs/ray-data\n",
      "2024-07-17 03:01:25,875\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> ActorPoolMapOperator[Map(GeneratePrompt)]\n",
      "                                                                                                                   2024-07-17 03:01:39,380\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-07-16_20-19-30_230780_1258974/logs/ray-data\n",
      "2024-07-17 03:01:39,380\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> ActorPoolMapOperator[Map(GetStatements)]\n",
      "                                                                                                                     2024-07-17 03:02:03,166\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-07-16_20-19-30_230780_1258974/logs/ray-data\n",
      "2024-07-17 03:02:03,166\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> ActorPoolMapOperator[Map(GeneratePrompt)]\n",
      "                                                                                                                   2024-07-17 03:02:16,911\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-07-16_20-19-30_230780_1258974/logs/ray-data\n",
      "2024-07-17 03:02:16,911\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> ActorPoolMapOperator[Map(GetModelOutputs)]\n",
      "                                                                                                                     2024-07-17 03:02:52,187\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-07-16_20-19-30_230780_1258974/logs/ray-data\n",
      "2024-07-17 03:02:52,188\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> ActorPoolMapOperator[Map(FaithfulnessScore)]\n",
      "                                                                                                                   2024-07-17 03:03:05,892\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-07-16_20-19-30_230780_1258974/logs/ray-data\n",
      "2024-07-17 03:03:05,893\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> AllToAllOperator[Aggregate] -> LimitOperator[limit=1]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                  \n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[AFile /home/ubuntu/efs/clarify_rag/rag_eval/results-eval-faithfulness/faithfulness_rag-dataset-refs-test-100.jsonl exists. Overwriting existing file\n",
      "2024-07-17 03:03:06,454\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-07-16_20-19-30_230780_1258974/logs/ray-data\n",
      "2024-07-17 03:03:06,455\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(<lambda>)]\n",
      "                                                                                                                    2024-07-17 03:03:08,082\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-07-16_20-19-30_230780_1258974/logs/ray-data\n",
      "2024-07-17 03:03:08,083\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(<lambda>)]\n",
      "                                                  "
     ]
    }
   ],
   "source": [
    "eval_algo = Faithfulness()\n",
    "eval_output = eval_algo.evaluate(judge_model=judge_model,\n",
    "                                 dataset_config=config,\n",
    "                                 long_form_prompt_template=long_form_prompt_template,\n",
    "                                 nli_statements_prompt_template=nli_statements_prompt_template,\n",
    "                                 num_records=100,\n",
    "                                 save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[EvalOutput(eval_name='faithfulness', dataset_name='rag-dataset-refs-test-100', dataset_scores=[EvalScore(name='faithfulness', value=0.9849047619047618, error=None)], prompt_template=None, category_scores=None, output_path='/home/ubuntu/efs/clarify_rag/rag_eval/results-eval-faithfulness/faithfulness_rag-dataset-refs-test-100.jsonl', error=None)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_input</th>\n",
       "      <th>model_output</th>\n",
       "      <th>target_context</th>\n",
       "      <th>raw_verdicts</th>\n",
       "      <th>raw_statements</th>\n",
       "      <th>statements_input_tokens</th>\n",
       "      <th>statements_output_tokens</th>\n",
       "      <th>input_tokens</th>\n",
       "      <th>output_tokens</th>\n",
       "      <th>scores</th>\n",
       "      <th>eval_algo</th>\n",
       "      <th>eval_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who is the companion of the Tenth Doctor in th...</td>\n",
       "      <td>The companion of the Tenth Doctor in the episo...</td>\n",
       "      <td>We'd Like To Thank You, Herbert Hoover, For Re...</td>\n",
       "      <td>&lt;judgements&gt;\\n&lt;judgement&gt;\\nStatement: The comp...</td>\n",
       "      <td>&lt;statements&gt;\\nStatement: The companion of the ...</td>\n",
       "      <td>341</td>\n",
       "      <td>34</td>\n",
       "      <td>1556</td>\n",
       "      <td>78</td>\n",
       "      <td>[{'name': 'faithfulness', 'value': 1.0}]</td>\n",
       "      <td>faithfulness</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What event did the Salem Regional Medical Cent...</td>\n",
       "      <td>The Salem Regional Medical Center Foundation p...</td>\n",
       "      <td>February 19, 2015 DETROIT (AP) — An appeals co...</td>\n",
       "      <td>&lt;judgements&gt;\\n&lt;judgement&gt;\\nStatement: The Sale...</td>\n",
       "      <td>&lt;statements&gt;\\nStatement: The Salem Regional Me...</td>\n",
       "      <td>336</td>\n",
       "      <td>44</td>\n",
       "      <td>1793</td>\n",
       "      <td>139</td>\n",
       "      <td>[{'name': 'faithfulness', 'value': 1.0}]</td>\n",
       "      <td>faithfulness</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When did the author realize their blogiversary...</td>\n",
       "      <td>The author realized their blogiversary was on ...</td>\n",
       "      <td>HAPPY belated BLOGIVERSARY!\\nFebruary 7, 2006\\...</td>\n",
       "      <td>&lt;judgements&gt;\\n&lt;judgement&gt;\\nStatement: The auth...</td>\n",
       "      <td>&lt;statements&gt;\\nStatement: The author realized t...</td>\n",
       "      <td>325</td>\n",
       "      <td>27</td>\n",
       "      <td>1772</td>\n",
       "      <td>87</td>\n",
       "      <td>[{'name': 'faithfulness', 'value': 1.0}]</td>\n",
       "      <td>faithfulness</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the main issue with using two Smart Ob...</td>\n",
       "      <td>The main issue with using two Smart Objects in...</td>\n",
       "      <td>In the previous post I cited a tool for Photos...</td>\n",
       "      <td>&lt;judgements&gt;\\n&lt;judgement&gt;\\nStatement: The main...</td>\n",
       "      <td>&lt;statements&gt;\\nStatement: The main issue with u...</td>\n",
       "      <td>429</td>\n",
       "      <td>113</td>\n",
       "      <td>2081</td>\n",
       "      <td>281</td>\n",
       "      <td>[{'name': 'faithfulness', 'value': 1.0}]</td>\n",
       "      <td>faithfulness</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the services offered by La Petrolifer...</td>\n",
       "      <td>La Petrolifera Italo Rumena (PIR) offers stora...</td>\n",
       "      <td>Flexibility, advanced logistic solutions and h...</td>\n",
       "      <td>&lt;judgements&gt;\\n&lt;judgement&gt;\\nStatement: La Petro...</td>\n",
       "      <td>&lt;statements&gt;\\nStatement: La Petrolifera Italo ...</td>\n",
       "      <td>413</td>\n",
       "      <td>158</td>\n",
       "      <td>1614</td>\n",
       "      <td>374</td>\n",
       "      <td>[{'name': 'faithfulness', 'value': 1.0}]</td>\n",
       "      <td>faithfulness</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>What is the new legislation about that could g...</td>\n",
       "      <td>The new legislation is about matching dollar-f...</td>\n",
       "      <td>Newly passed legislation could give Holbrook s...</td>\n",
       "      <td>&lt;judgements&gt;\\n&lt;judgement&gt;\\nStatement: The new ...</td>\n",
       "      <td>&lt;statements&gt;\\nStatement: The new legislation i...</td>\n",
       "      <td>385</td>\n",
       "      <td>88</td>\n",
       "      <td>1712</td>\n",
       "      <td>242</td>\n",
       "      <td>[{'name': 'faithfulness', 'value': 1.0}]</td>\n",
       "      <td>faithfulness</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>How do politicians use public demographics and...</td>\n",
       "      <td>Politicians use public demographics and statis...</td>\n",
       "      <td>Yesterday, a few co-workers and myself, were s...</td>\n",
       "      <td>&lt;judgements&gt;\\n&lt;judgement&gt;\\nStatement: Politici...</td>\n",
       "      <td>&lt;statements&gt;\\nStatement: Politicians use publi...</td>\n",
       "      <td>332</td>\n",
       "      <td>47</td>\n",
       "      <td>1025</td>\n",
       "      <td>139</td>\n",
       "      <td>[{'name': 'faithfulness', 'value': 1.0}]</td>\n",
       "      <td>faithfulness</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>What are the two primary personas that need to...</td>\n",
       "      <td>The two primary personas that need to be ackno...</td>\n",
       "      <td>If you’re struggling to sell more managed serv...</td>\n",
       "      <td>&lt;judgements&gt;\\n&lt;judgement&gt;\\nStatement: The two ...</td>\n",
       "      <td>&lt;statements&gt;\\nStatement: The two primary perso...</td>\n",
       "      <td>348</td>\n",
       "      <td>42</td>\n",
       "      <td>1955</td>\n",
       "      <td>100</td>\n",
       "      <td>[{'name': 'faithfulness', 'value': 1.0}]</td>\n",
       "      <td>faithfulness</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>What does KatyKatCafe look forward to during #...</td>\n",
       "      <td>KatyKatCafe looks forward to Boogie with the B...</td>\n",
       "      <td>.\\nKatyKatCafe @BunnyJeanCook Just read the sa...</td>\n",
       "      <td>&lt;judgements&gt;\\n&lt;judgement&gt;\\nStatement: KatyKatC...</td>\n",
       "      <td>&lt;statements&gt;\\nStatement: KatyKatCafe looks for...</td>\n",
       "      <td>348</td>\n",
       "      <td>40</td>\n",
       "      <td>1320</td>\n",
       "      <td>154</td>\n",
       "      <td>[{'name': 'faithfulness', 'value': 1.0}]</td>\n",
       "      <td>faithfulness</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>What are the window trends for 2019 according ...</td>\n",
       "      <td>The window trends for 2019 include larger wind...</td>\n",
       "      <td>WINDOW TRENDS FOR 2019\\nWindows continue to gr...</td>\n",
       "      <td>&lt;judgements&gt;\\n&lt;judgement&gt;\\nStatement: The wind...</td>\n",
       "      <td>&lt;statements&gt;\\nStatement: The window trends for...</td>\n",
       "      <td>402</td>\n",
       "      <td>132</td>\n",
       "      <td>1475</td>\n",
       "      <td>452</td>\n",
       "      <td>[{'name': 'faithfulness', 'value': 1.0}]</td>\n",
       "      <td>faithfulness</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          model_input  \\\n",
       "0   Who is the companion of the Tenth Doctor in th...   \n",
       "1   What event did the Salem Regional Medical Cent...   \n",
       "2   When did the author realize their blogiversary...   \n",
       "3   What is the main issue with using two Smart Ob...   \n",
       "4   What are the services offered by La Petrolifer...   \n",
       "..                                                ...   \n",
       "95  What is the new legislation about that could g...   \n",
       "96  How do politicians use public demographics and...   \n",
       "97  What are the two primary personas that need to...   \n",
       "98  What does KatyKatCafe look forward to during #...   \n",
       "99  What are the window trends for 2019 according ...   \n",
       "\n",
       "                                         model_output  \\\n",
       "0   The companion of the Tenth Doctor in the episo...   \n",
       "1   The Salem Regional Medical Center Foundation p...   \n",
       "2   The author realized their blogiversary was on ...   \n",
       "3   The main issue with using two Smart Objects in...   \n",
       "4   La Petrolifera Italo Rumena (PIR) offers stora...   \n",
       "..                                                ...   \n",
       "95  The new legislation is about matching dollar-f...   \n",
       "96  Politicians use public demographics and statis...   \n",
       "97  The two primary personas that need to be ackno...   \n",
       "98  KatyKatCafe looks forward to Boogie with the B...   \n",
       "99  The window trends for 2019 include larger wind...   \n",
       "\n",
       "                                       target_context  \\\n",
       "0   We'd Like To Thank You, Herbert Hoover, For Re...   \n",
       "1   February 19, 2015 DETROIT (AP) — An appeals co...   \n",
       "2   HAPPY belated BLOGIVERSARY!\\nFebruary 7, 2006\\...   \n",
       "3   In the previous post I cited a tool for Photos...   \n",
       "4   Flexibility, advanced logistic solutions and h...   \n",
       "..                                                ...   \n",
       "95  Newly passed legislation could give Holbrook s...   \n",
       "96  Yesterday, a few co-workers and myself, were s...   \n",
       "97  If you’re struggling to sell more managed serv...   \n",
       "98  .\\nKatyKatCafe @BunnyJeanCook Just read the sa...   \n",
       "99  WINDOW TRENDS FOR 2019\\nWindows continue to gr...   \n",
       "\n",
       "                                         raw_verdicts  \\\n",
       "0   <judgements>\\n<judgement>\\nStatement: The comp...   \n",
       "1   <judgements>\\n<judgement>\\nStatement: The Sale...   \n",
       "2   <judgements>\\n<judgement>\\nStatement: The auth...   \n",
       "3   <judgements>\\n<judgement>\\nStatement: The main...   \n",
       "4   <judgements>\\n<judgement>\\nStatement: La Petro...   \n",
       "..                                                ...   \n",
       "95  <judgements>\\n<judgement>\\nStatement: The new ...   \n",
       "96  <judgements>\\n<judgement>\\nStatement: Politici...   \n",
       "97  <judgements>\\n<judgement>\\nStatement: The two ...   \n",
       "98  <judgements>\\n<judgement>\\nStatement: KatyKatC...   \n",
       "99  <judgements>\\n<judgement>\\nStatement: The wind...   \n",
       "\n",
       "                                       raw_statements  \\\n",
       "0   <statements>\\nStatement: The companion of the ...   \n",
       "1   <statements>\\nStatement: The Salem Regional Me...   \n",
       "2   <statements>\\nStatement: The author realized t...   \n",
       "3   <statements>\\nStatement: The main issue with u...   \n",
       "4   <statements>\\nStatement: La Petrolifera Italo ...   \n",
       "..                                                ...   \n",
       "95  <statements>\\nStatement: The new legislation i...   \n",
       "96  <statements>\\nStatement: Politicians use publi...   \n",
       "97  <statements>\\nStatement: The two primary perso...   \n",
       "98  <statements>\\nStatement: KatyKatCafe looks for...   \n",
       "99  <statements>\\nStatement: The window trends for...   \n",
       "\n",
       "    statements_input_tokens  statements_output_tokens  input_tokens  \\\n",
       "0                       341                        34          1556   \n",
       "1                       336                        44          1793   \n",
       "2                       325                        27          1772   \n",
       "3                       429                       113          2081   \n",
       "4                       413                       158          1614   \n",
       "..                      ...                       ...           ...   \n",
       "95                      385                        88          1712   \n",
       "96                      332                        47          1025   \n",
       "97                      348                        42          1955   \n",
       "98                      348                        40          1320   \n",
       "99                      402                       132          1475   \n",
       "\n",
       "    output_tokens                                    scores     eval_algo  \\\n",
       "0              78  [{'name': 'faithfulness', 'value': 1.0}]  faithfulness   \n",
       "1             139  [{'name': 'faithfulness', 'value': 1.0}]  faithfulness   \n",
       "2              87  [{'name': 'faithfulness', 'value': 1.0}]  faithfulness   \n",
       "3             281  [{'name': 'faithfulness', 'value': 1.0}]  faithfulness   \n",
       "4             374  [{'name': 'faithfulness', 'value': 1.0}]  faithfulness   \n",
       "..            ...                                       ...           ...   \n",
       "95            242  [{'name': 'faithfulness', 'value': 1.0}]  faithfulness   \n",
       "96            139  [{'name': 'faithfulness', 'value': 1.0}]  faithfulness   \n",
       "97            100  [{'name': 'faithfulness', 'value': 1.0}]  faithfulness   \n",
       "98            154  [{'name': 'faithfulness', 'value': 1.0}]  faithfulness   \n",
       "99            452  [{'name': 'faithfulness', 'value': 1.0}]  faithfulness   \n",
       "\n",
       "    eval_score  \n",
       "0          1.0  \n",
       "1          1.0  \n",
       "2          1.0  \n",
       "3          1.0  \n",
       "4          1.0  \n",
       "..         ...  \n",
       "95         1.0  \n",
       "96         1.0  \n",
       "97         1.0  \n",
       "98         1.0  \n",
       "99         1.0  \n",
       "\n",
       "[100 rows x 12 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Pandas DataFrame to visualize the results\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "data = []\n",
    "with open(os.path.join(eval_results_path, \"faithfulness_rag-dataset-refs-test-100.jsonl\"), \"r\") as file:\n",
    "    for line in file:\n",
    "        data.append(json.loads(line))\n",
    "df = pd.DataFrame(data)\n",
    "df['eval_algo'] = df['scores'].apply(lambda x: x[0]['name'])\n",
    "df['eval_score'] = df['scores'].apply(lambda x: x[0]['value'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_df = df[df['eval_score'] < 1]\n",
    "if len(errors_df):\n",
    "    errors_df.to_csv(f'faithfulness_{model_id}_errors.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute total cost of running judge model on the dataset\n",
    "token_cost = claude3_cost[model_id]\n",
    "total_input_tokens = df['statements_input_tokens'].sum() + df['input_tokens'].sum()\n",
    "total_output_tokens = df['statements_output_tokens'].sum() + df['output_tokens'].sum()\n",
    "input_token_cost = (token_cost['pp1k_input_tokens'] * total_input_tokens) / 1000\n",
    "output_token_cost = (token_cost['pp1k_output_tokens'] * total_output_tokens) / 1000\n",
    "total_cost = input_token_cost + output_token_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean faithfulness score 0.9849\n",
      "Std faithfulness score 0.1037\n",
      "Total cost $0.0917\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean faithfulness score {df['eval_score'].mean():.4f}\")\n",
    "print(f\"Std faithfulness score {df['eval_score'].std():.4f}\")\n",
    "print(f\"Total cost ${total_cost:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f'faithfulness_{model_id}_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmeval_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
